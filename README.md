# Machine Unlearning with Data Augmentation

This repository contains **extended results tables** from the paper:  
**_Audio Augmentation Meets Audio Unlearning: Help or Hinder?_**

Due to ICASSP page constraints, the full experimental results (large tables with detailed metrics) could not be included in the main paper. This repo serves as a companion resource where the complete tables are made available in a clean, citable format.

---

## ğŸ“Š Tables

Each table reports detailed evaluation metrics for machine unlearning experiments across different **audio classification datasets**.  
The metrics include average accuracy, forgetting gap, membership inference attack (MIA) resistance, and more.

---

### ğŸµ Table 1: ESC-10

Results on the **ESC-10 dataset** (environmental sound classification).  
Click to view the full PDF with all metrics.

[![ESC-10 Results](assets/esc10.png)](esc10.pdf)

---

### ğŸ—£ï¸ Table 2: SpeechCommands

Results on the **Google SpeechCommands dataset** (keyword spotting).  
Click to view the full PDF with all metrics.

[![SpeechCommands Results](assets/speechcommands.png)](speechcommands.pdf)

---

### ğŸŒ† Table 3: UrbanSound8K

Results on the **UrbanSound8K dataset** (urban audio classification).  
Click to view the full PDF with all metrics.

[![UrbanSound8K Results](assets/urbansound8k.png)](urbansound8k.pdf)

---

## ğŸ” Why This Repo?

Machine unlearning is the process of selectively removing the influence of specific data points (or subsets) from a trained model, **without retraining from scratch**.

In this project, we study how **audio data augmentations**â€”which are common in training pipelinesâ€”interact with unlearning algorithms.

- Do augmentations **help models forget faster**?
- Or do they **leave residual traces**, making forgetting harder?

This repo hosts the **supplementary tables** that provide detailed insights into these questions.

---
